{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "USkA-oB3Q9XD",
        "outputId": "4541b89c-c1c3-4e05-d63e-540b2784cbc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from -r requiremnets_notebook.txt (line 1)) (0.3.0)\n",
            "Requirement already satisfied: langchain-community in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from -r requiremnets_notebook.txt (line 2)) (0.3.0)\n",
            "Requirement already satisfied: langchain-chroma in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from -r requiremnets_notebook.txt (line 3)) (0.1.4)\n",
            "Collecting langchain_huggingface (from -r requiremnets_notebook.txt (line 4))\n",
            "  Downloading langchain_huggingface-0.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: transformers in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from -r requiremnets_notebook.txt (line 5)) (4.44.2)\n",
            "Requirement already satisfied: sentence-transformers in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from -r requiremnets_notebook.txt (line 6)) (3.1.0)\n",
            "Requirement already satisfied: chromadb in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from -r requiremnets_notebook.txt (line 7)) (0.5.3)\n",
            "Requirement already satisfied: torch in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from -r requiremnets_notebook.txt (line 8)) (2.4.1)\n",
            "Requirement already satisfied: pypdf in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from -r requiremnets_notebook.txt (line 9)) (4.3.1)\n",
            "Requirement already satisfied: python-dotenv in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from -r requiremnets_notebook.txt (line 10)) (1.0.1)\n",
            "Collecting langchain_experimental (from -r requiremnets_notebook.txt (line 11))\n",
            "  Downloading langchain_experimental-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from langchain->-r requiremnets_notebook.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from langchain->-r requiremnets_notebook.txt (line 1)) (2.0.34)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from langchain->-r requiremnets_notebook.txt (line 1)) (3.10.5)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from langchain->-r requiremnets_notebook.txt (line 1)) (0.3.9)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from langchain->-r requiremnets_notebook.txt (line 1)) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from langchain->-r requiremnets_notebook.txt (line 1)) (0.1.131)\n",
            "Requirement already satisfied: numpy<2,>=1 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from langchain->-r requiremnets_notebook.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from langchain->-r requiremnets_notebook.txt (line 1)) (2.9.1)\n",
            "Requirement already satisfied: requests<3,>=2 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from langchain->-r requiremnets_notebook.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from langchain->-r requiremnets_notebook.txt (line 1)) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from langchain-community->-r requiremnets_notebook.txt (line 2)) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from langchain-community->-r requiremnets_notebook.txt (line 2)) (2.5.2)\n",
            "Requirement already satisfied: fastapi<1,>=0.95.2 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from langchain-chroma->-r requiremnets_notebook.txt (line 3)) (0.114.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from langchain_huggingface->-r requiremnets_notebook.txt (line 4)) (0.24.7)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from langchain_huggingface->-r requiremnets_notebook.txt (line 4)) (0.19.1)\n",
            "Requirement already satisfied: filelock in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from transformers->-r requiremnets_notebook.txt (line 5)) (3.16.0)\n",
            "Requirement already satisfied: packaging>=20.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from transformers->-r requiremnets_notebook.txt (line 5)) (24.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from transformers->-r requiremnets_notebook.txt (line 5)) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from transformers->-r requiremnets_notebook.txt (line 5)) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from transformers->-r requiremnets_notebook.txt (line 5)) (4.66.5)\n",
            "Requirement already satisfied: scikit-learn in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from sentence-transformers->-r requiremnets_notebook.txt (line 6)) (1.5.2)\n",
            "Requirement already satisfied: scipy in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from sentence-transformers->-r requiremnets_notebook.txt (line 6)) (1.14.1)\n",
            "Requirement already satisfied: Pillow in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from sentence-transformers->-r requiremnets_notebook.txt (line 6)) (10.4.0)\n",
            "Requirement already satisfied: build>=1.0.3 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from chromadb->-r requiremnets_notebook.txt (line 7)) (1.2.2)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from chromadb->-r requiremnets_notebook.txt (line 7)) (0.7.3)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requiremnets_notebook.txt (line 7)) (0.30.6)\n",
            "Requirement already satisfied: posthog>=2.4.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from chromadb->-r requiremnets_notebook.txt (line 7)) (3.6.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from chromadb->-r requiremnets_notebook.txt (line 7)) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from chromadb->-r requiremnets_notebook.txt (line 7)) (1.19.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from chromadb->-r requiremnets_notebook.txt (line 7)) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from chromadb->-r requiremnets_notebook.txt (line 7)) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from chromadb->-r requiremnets_notebook.txt (line 7)) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from chromadb->-r requiremnets_notebook.txt (line 7)) (1.27.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from chromadb->-r requiremnets_notebook.txt (line 7)) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from chromadb->-r requiremnets_notebook.txt (line 7)) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from chromadb->-r requiremnets_notebook.txt (line 7)) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from chromadb->-r requiremnets_notebook.txt (line 7)) (1.66.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from chromadb->-r requiremnets_notebook.txt (line 7)) (4.2.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from chromadb->-r requiremnets_notebook.txt (line 7)) (0.12.5)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from chromadb->-r requiremnets_notebook.txt (line 7)) (30.1.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from chromadb->-r requiremnets_notebook.txt (line 7)) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from chromadb->-r requiremnets_notebook.txt (line 7)) (3.10.7)\n",
            "Requirement already satisfied: httpx>=0.27.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from chromadb->-r requiremnets_notebook.txt (line 7)) (0.27.2)\n",
            "Requirement already satisfied: sympy in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from torch->-r requiremnets_notebook.txt (line 8)) (1.13.2)\n",
            "Requirement already satisfied: networkx in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from torch->-r requiremnets_notebook.txt (line 8)) (3.3)\n",
            "Requirement already satisfied: jinja2 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from torch->-r requiremnets_notebook.txt (line 8)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from torch->-r requiremnets_notebook.txt (line 8)) (2024.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requiremnets_notebook.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requiremnets_notebook.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requiremnets_notebook.txt (line 1)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requiremnets_notebook.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requiremnets_notebook.txt (line 1)) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requiremnets_notebook.txt (line 1)) (1.11.1)\n",
            "Requirement already satisfied: pyproject_hooks in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from build>=1.0.3->chromadb->-r requiremnets_notebook.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: colorama in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from build>=1.0.3->chromadb->-r requiremnets_notebook.txt (line 7)) (0.4.6)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requiremnets_notebook.txt (line 2)) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requiremnets_notebook.txt (line 2)) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from fastapi<1,>=0.95.2->langchain-chroma->-r requiremnets_notebook.txt (line 3)) (0.38.5)\n",
            "Requirement already satisfied: anyio in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from httpx>=0.27.0->chromadb->-r requiremnets_notebook.txt (line 7)) (4.4.0)\n",
            "Requirement already satisfied: certifi in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from httpx>=0.27.0->chromadb->-r requiremnets_notebook.txt (line 7)) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from httpx>=0.27.0->chromadb->-r requiremnets_notebook.txt (line 7)) (1.0.5)\n",
            "Requirement already satisfied: idna in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from httpx>=0.27.0->chromadb->-r requiremnets_notebook.txt (line 7)) (3.8)\n",
            "Requirement already satisfied: sniffio in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from httpx>=0.27.0->chromadb->-r requiremnets_notebook.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb->-r requiremnets_notebook.txt (line 7)) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requiremnets_notebook.txt (line 7)) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requiremnets_notebook.txt (line 7)) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requiremnets_notebook.txt (line 7)) (2.34.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requiremnets_notebook.txt (line 7)) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requiremnets_notebook.txt (line 7)) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requiremnets_notebook.txt (line 7)) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requiremnets_notebook.txt (line 7)) (2.2.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain->-r requiremnets_notebook.txt (line 1)) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain->-r requiremnets_notebook.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: coloredlogs in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requiremnets_notebook.txt (line 7)) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requiremnets_notebook.txt (line 7)) (24.3.25)\n",
            "Requirement already satisfied: protobuf in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requiremnets_notebook.txt (line 7)) (4.25.4)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requiremnets_notebook.txt (line 7)) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requiremnets_notebook.txt (line 7)) (8.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requiremnets_notebook.txt (line 7)) (1.65.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requiremnets_notebook.txt (line 7)) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.27.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requiremnets_notebook.txt (line 7)) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requiremnets_notebook.txt (line 7)) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.48b0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requiremnets_notebook.txt (line 7)) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requiremnets_notebook.txt (line 7)) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.48b0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requiremnets_notebook.txt (line 7)) (0.48b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requiremnets_notebook.txt (line 7)) (65.5.0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requiremnets_notebook.txt (line 7)) (1.16.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requiremnets_notebook.txt (line 7)) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from posthog>=2.4.0->chromadb->-r requiremnets_notebook.txt (line 7)) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from posthog>=2.4.0->chromadb->-r requiremnets_notebook.txt (line 7)) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requiremnets_notebook.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requiremnets_notebook.txt (line 1)) (2.23.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langchain->-r requiremnets_notebook.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->-r requiremnets_notebook.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: click>=8.0.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from typer>=0.9.0->chromadb->-r requiremnets_notebook.txt (line 7)) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from typer>=0.9.0->chromadb->-r requiremnets_notebook.txt (line 7)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from typer>=0.9.0->chromadb->-r requiremnets_notebook.txt (line 7)) (13.8.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requiremnets_notebook.txt (line 7)) (0.6.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requiremnets_notebook.txt (line 7)) (0.24.0)\n",
            "Requirement already satisfied: websockets>=10.4 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requiremnets_notebook.txt (line 7)) (13.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from jinja2->torch->-r requiremnets_notebook.txt (line 8)) (2.1.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers->-r requiremnets_notebook.txt (line 6)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers->-r requiremnets_notebook.txt (line 6)) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from sympy->torch->-r requiremnets_notebook.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requiremnets_notebook.txt (line 7)) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requiremnets_notebook.txt (line 7)) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requiremnets_notebook.txt (line 7)) (4.9)\n",
            "Requirement already satisfied: zipp>=0.5 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requiremnets_notebook.txt (line 7)) (3.20.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain->-r requiremnets_notebook.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb->-r requiremnets_notebook.txt (line 7)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb->-r requiremnets_notebook.txt (line 7)) (2.18.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->-r requiremnets_notebook.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb->-r requiremnets_notebook.txt (line 7)) (10.0)\n",
            "Requirement already satisfied: pyreadline3 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb->-r requiremnets_notebook.txt (line 7)) (3.4.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb->-r requiremnets_notebook.txt (line 7)) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in e:\\cse299\\chatbot\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requiremnets_notebook.txt (line 7)) (0.6.1)\n",
            "Downloading langchain_huggingface-0.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading langchain_experimental-0.3.2-py3-none-any.whl (208 kB)\n",
            "Installing collected packages: langchain_huggingface, langchain_experimental\n",
            "Successfully installed langchain_experimental-0.3.2 langchain_huggingface-0.1.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -r requiremnets.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set paths in your notebook\n",
        "model_path = \"E:/CSE299/chatbot/llm\"\n",
        "embedding_save_path = \"E:/CSE299/chatbot/Embedding\"\n",
        "pdfs_path = \"E:/CSE299/chatbot/docs\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6GFLqJPU-Ly"
      },
      "source": [
        "\n",
        "\n",
        "## ** title Run this to terminal**\n",
        "\n",
        " curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        " ollama serve\n",
        "\n",
        " ollama pull llama3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_sjR08t8PaHb"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "\n",
        "def serve_ollama():\n",
        "    \"\"\"Starts Ollama server.\"\"\"\n",
        "    serve_command = \"ollama serve\"\n",
        "    try:\n",
        "        subprocess.run(serve_command, shell=True, check=True)\n",
        "        print(\"Ollama server is running.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Failed to start Ollama server: {e}\")\n",
        "        return\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2rs6kPThFrq",
        "outputId": "408a168a-d9f8-49b7-96b6-658783a0947c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            "\n",
            "Ollama installed successfully.\n"
          ]
        }
      ],
      "source": [
        "# install_ollama()   # Install Ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhsJ1auLhGTq"
      },
      "outputs": [],
      "source": [
        "# serve_ollama()     # Start the Ollama server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykjqYE-IhIFa"
      },
      "outputs": [],
      "source": [
        "# pull_model()       # Pull Llama3 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tBCONJnCRW2_"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
        "from langchain_community.llms.ollama import Ollama\n",
        "from langchain import hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chunking & PDF loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7znFTCZ7RkuK"
      },
      "outputs": [],
      "source": [
        "#@title Function to load all PDFs from a given directory using PyPDFDirectoryLoader.\n",
        "\n",
        "def load_pdfs_from_directory(directory_path):\n",
        "\n",
        "    loader = PyPDFDirectoryLoader(directory_path)\n",
        "    docs = loader.load()\n",
        "    return docs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Recursive Chunking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "a8QgoYoxSO-_"
      },
      "outputs": [],
      "source": [
        "#@title recursive Chuking of the documents\n",
        "\n",
        "def recursive_chunks(documents, chunk_size, chunk_overlap):\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap, add_start_index=True)\n",
        "    all_splits = text_splitter.split_documents(documents)\n",
        "\n",
        "    return all_splits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Character Chunking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBHvCyMk6Vhw"
      },
      "outputs": [],
      "source": [
        "#@title character Chuking of the documents\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "\n",
        "def character_chunks(documents, chunk_size, chunk_overlap):\n",
        "\n",
        "    # Initialize the CharacterTextSplitter with specified parameters\n",
        "    splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\\n\",\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "        length_function=len,\n",
        "        is_separator_regex=False,\n",
        "    )\n",
        "\n",
        "    # Split the text into chunks for each document\n",
        "    # all_chunks = []\n",
        "    # for doc in documents:\n",
        "    #     # Split each document's content and extend the list\n",
        "    #     chunks = splitter.split_text(doc.page_content)\n",
        "    #     all_chunks.extend(chunks)\n",
        "    all_chunks = splitter.split_documents(documents)\n",
        "\n",
        "    return all_chunks\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Semantic Chunking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7rmuGHEaKoA"
      },
      "outputs": [],
      "source": [
        "#@title semantic Chuking of the documents\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "def semantic_chunks(documents, embed_model):\n",
        "\n",
        "    semantic_chunker = SemanticChunker(embed_model, breakpoint_threshold_type=\"percentile\")\n",
        "\n",
        "    # Create semantic chunks from the documents' content\n",
        "    semantic_chunks = semantic_chunker.create_documents([d.page_content for d in documents])\n",
        "\n",
        "    return semantic_chunks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Intializing Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Embedding Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dWFcj5XSp1Ka"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "def get_embedding_model(model_name, model_kwargs, path):\n",
        "    encode_kwargs = {'normalize_embeddings': True}\n",
        "\n",
        "    # Initialize HuggingFaceEmbeddings with model name and kwargs\n",
        "    hf = HuggingFaceEmbeddings(\n",
        "        model_name=model_name,\n",
        "        model_kwargs=model_kwargs,\n",
        "        encode_kwargs=encode_kwargs,\n",
        "        cache_folder=path\n",
        "    )\n",
        "\n",
        "    return hf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LLM (Ollama model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OkLniAhdCQS3"
      },
      "outputs": [],
      "source": [
        "# @title get Ollama model\n",
        "\n",
        "from langchain_community.llms import Ollama\n",
        "\n",
        "def get_ollama_model(model):\n",
        "    llm = Ollama(model=model)\n",
        "    return llm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  Embedding "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "9cfbbcde5fbc4edca77c0eef1c705d36",
            "8f0cb74e78764a89acffa3a4e818e888",
            "8e69cc838456455c8953a41b28503dab",
            "7cc1bb1287a747e58598d42e08845476",
            "f17e27493b4846e1ab086ea7a6f7654e",
            "7119cc97380a473f88c28732b2c0b484",
            "56aec4fb098b461cabab190b64dd9373",
            "c2652477e7c04bc9965b80f96e2caf16",
            "c607deeff00b4e3a976493ed9a3c603d",
            "95baf5e616ed4254a8073da5a4577320",
            "1789b8c51c4b48118e34ffedce61dd47"
          ]
        },
        "id": "sw8hKqtzp506",
        "outputId": "6b64bd22-5af7-45e6-b37d-167e8d3c2b4c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cfbbcde5fbc4edca77c0eef1c705d36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/547M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:transformers_modules.nomic-ai.nomic-bert-2048.c1b1fd7a715b8eb2e232d34593154ac782c98ac9.modeling_hf_nomic_bert:<All keys matched successfully>\n"
          ]
        }
      ],
      "source": [
        "# # @title Load embedding model\n",
        "# from transformers import AutoModel\n",
        "# embedding_model_name = \"nomic-ai/nomic-embed-text-v1.5\"\n",
        "# model_kwargs = {'device': 'cpu', 'trust_remote_code': True}  # Pass trust_remote_code here\n",
        "# embedding = get_embedding_model(embedding_model_name, model_kwargs, path=\"embeddings/nomic/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Assuming get_embedding_model is defined to support a 'path' argument for saving locally\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[43mget_embedding_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_model_save_path\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[4], line 7\u001b[0m, in \u001b[0;36mget_embedding_model\u001b[1;34m(model_name, model_kwargs, path)\u001b[0m\n\u001b[0;32m      4\u001b[0m encode_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalize_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Initialize HuggingFaceEmbeddings with model name and kwargs\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m hf \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hf\n",
            "File \u001b[1;32me:\\CSE299\\chatbot\\venv\\Lib\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:60\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import sentence_transformers python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     58\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43msentence_transformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32me:\\CSE299\\chatbot\\venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:294\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[1;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data)\u001b[0m\n\u001b[0;32m    285\u001b[0m         model_name_or_path \u001b[38;5;241m=\u001b[39m __MODEL_HUB_ORGANIZATION__ \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_name_or_path\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sentence_transformer_model(\n\u001b[0;32m    288\u001b[0m     model_name_or_path,\n\u001b[0;32m    289\u001b[0m     token,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    292\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    293\u001b[0m ):\n\u001b[1;32m--> 294\u001b[0m     modules, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(\n\u001b[0;32m    307\u001b[0m         model_name_or_path,\n\u001b[0;32m    308\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    315\u001b[0m         config_kwargs\u001b[38;5;241m=\u001b[39mconfig_kwargs,\n\u001b[0;32m    316\u001b[0m     )\n",
            "File \u001b[1;32me:\\CSE299\\chatbot\\venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1647\u001b[0m, in \u001b[0;36mSentenceTransformer._load_sbert_model\u001b[1;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[0m\n\u001b[0;32m   1644\u001b[0m \u001b[38;5;66;03m# Try to initialize the module with a lot of kwargs, but only if the module supports them\u001b[39;00m\n\u001b[0;32m   1645\u001b[0m \u001b[38;5;66;03m# Otherwise we fall back to the load method\u001b[39;00m\n\u001b[0;32m   1646\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1647\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mmodule_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1648\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   1649\u001b[0m     module \u001b[38;5;241m=\u001b[39m module_class\u001b[38;5;241m.\u001b[39mload(model_name_or_path)\n",
            "File \u001b[1;32me:\\CSE299\\chatbot\\venv\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:56\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[1;34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path)\u001b[0m\n\u001b[0;32m     53\u001b[0m     config_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     55\u001b[0m config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_args, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir)\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_seq_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_max_length\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tokenizer_args:\n\u001b[0;32m     59\u001b[0m     tokenizer_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_max_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m max_seq_length\n",
            "File \u001b[1;32me:\\CSE299\\chatbot\\venv\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:87\u001b[0m, in \u001b[0;36mTransformer._load_model\u001b[1;34m(self, model_name_or_path, config, cache_dir, **model_args)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_mt5_model(model_name_or_path, config, cache_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32me:\\CSE299\\chatbot\\venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:559\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    558\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mregister(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, model_class, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n",
            "File \u001b[1;32m~\\.cache\\huggingface\\modules\\transformers_modules\\nomic-ai\\nomic-bert-2048\\c1b1fd7a715b8eb2e232d34593154ac782c98ac9\\modeling_hf_nomic_bert.py:431\u001b[0m, in \u001b[0;36mNomicBertPreTrainedModel.from_pretrained\u001b[1;34m(cls, model_name, config, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    428\u001b[0m     load_return \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;66;03m# TODO: can probably check config class and see if we need to remap from a bert model\u001b[39;00m\n\u001b[1;32m--> 431\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mstate_dict_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    432\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m remap_bert_state_dict(\n\u001b[0;32m    433\u001b[0m         state_dict,\n\u001b[0;32m    434\u001b[0m         config,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    437\u001b[0m         add_pooling_layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd_pooling_layer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m    438\u001b[0m     )\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ignore_mismatched_shapes:\n",
            "File \u001b[1;32m~\\.cache\\huggingface\\modules\\transformers_modules\\nomic-ai\\nomic-bert-2048\\c1b1fd7a715b8eb2e232d34593154ac782c98ac9\\modeling_hf_nomic_bert.py:74\u001b[0m, in \u001b[0;36mstate_dict_from_pretrained\u001b[1;34m(model_name, safe_serialization, device, dtype)\u001b[0m\n\u001b[0;32m     72\u001b[0m resolved_archive_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m weight_name \u001b[38;5;129;01min\u001b[39;00m [WEIGHTS_NAME, SAFE_WEIGHTS_NAME, WEIGHTS_INDEX_NAME, SAFE_WEIGHTS_INDEX_NAME]:\n\u001b[1;32m---> 74\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m weight_name \u001b[38;5;129;01min\u001b[39;00m [SAFE_WEIGHTS_NAME, SAFE_WEIGHTS_INDEX_NAME]:\n",
            "File \u001b[1;32me:\\CSE299\\chatbot\\venv\\Lib\\site-packages\\transformers\\utils\\hub.py:402\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    399\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    417\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
            "File \u001b[1;32me:\\CSE299\\chatbot\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m         message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m custom_message\n\u001b[0;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32me:\\CSE299\\chatbot\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32me:\\CSE299\\chatbot\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1240\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[0;32m   1221\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[0;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[0;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[0;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[0;32m   1255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32me:\\CSE299\\chatbot\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1389\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m   1387\u001b[0m Path(lock_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1399\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pointer_path):\n\u001b[0;32m   1400\u001b[0m         _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[1;32me:\\CSE299\\chatbot\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1916\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[1;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[0;32m   1913\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m   1914\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m-> 1916\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1923\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1925\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1926\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
            "File \u001b[1;32me:\\CSE299\\chatbot\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:549\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[0;32m    547\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 549\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDOWNLOAD_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# filter out keep-alive new chunks\u001b[39;49;00m\n\u001b[0;32m    551\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32me:\\CSE299\\chatbot\\venv\\Lib\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
            "File \u001b[1;32me:\\CSE299\\chatbot\\venv\\Lib\\site-packages\\urllib3\\response.py:1060\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1060\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1062\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m   1063\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
            "File \u001b[1;32me:\\CSE299\\chatbot\\venv\\Lib\\site-packages\\urllib3\\response.py:949\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[0;32m    947\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[1;32m--> 949\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    951\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[1;32me:\\CSE299\\chatbot\\venv\\Lib\\site-packages\\urllib3\\response.py:873\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    870\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 873\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m    875\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m    876\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[0;32m    883\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
            "File \u001b[1;32me:\\CSE299\\chatbot\\venv\\Lib\\site-packages\\urllib3\\response.py:856\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 465\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1276\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1277\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "from transformers import AutoModel\n",
        "\n",
        "\n",
        "# Define paths for saving the embedding model and vector database\n",
        "embedding_model_save_path = r\"E:\\CSE299\\chatbot\\llm\\nomic\"\n",
        "embedding_vector_db_path = r\"E:\\CSE299\\chatbot\\Embedding\\nomic\"\n",
        "\n",
        "# Ensure directories exist\n",
        "os.makedirs(embedding_model_save_path, exist_ok=True)\n",
        "os.makedirs(embedding_vector_db_path, exist_ok=True)\n",
        "\n",
        "# Load the embedding model and specify the local save path for the model\n",
        "embedding_model_name = \"nomic-ai/nomic-embed-text-v1.5\"\n",
        "model_kwargs = {'device': 'cpu', 'trust_remote_code': True}\n",
        "\n",
        "# Assuming get_embedding_model is defined to support a 'path' argument for saving locally\n",
        "embedding = get_embedding_model(embedding_model_name, model_kwargs, path=embedding_model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRwwZI1in_MZ"
      },
      "outputs": [],
      "source": [
        "sem_embedding = embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Access the underlying model from the HuggingFaceEmbeddings instance\n",
        "hf_model = embedding.client  # 'client' holds the underlying Hugging Face model\n",
        "\n",
        "# Get the embedding dimension using the dedicated method\n",
        "embedding_dim = hf_model.get_sentence_embedding_dimension()\n",
        "\n",
        "# Print the embedding dimension\n",
        "print(f\"Embedding Dimension: {embedding_dim}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Make Chunks "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3sqNNKfS7_B"
      },
      "outputs": [],
      "source": [
        "#@title chunking\n",
        "\n",
        "docs = load_pdfs_from_directory(pdfs_path)\n",
        "\n",
        "all_splits = recursive_chunks(docs, 1000, 200);\n",
        "# all_splits = semantic_chunks(docs, sem_embedding);\n",
        "# all_splits = character_chunks(docs, 1000, 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "TRnu-wXpC9eg",
        "outputId": "a24647cc-97a2-4414-c6e8-c627a0d36890"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'all_splits' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-2b006c55237a>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#vectorstoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mvectorstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChroma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersist_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'db/nomic/semantic/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mretriever\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_retriever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"similarity\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"k\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_splits' is not defined"
          ]
        }
      ],
      "source": [
        "#@title dbstore\n",
        "\n",
        "#vectorstoring\n",
        "vectorstore = Chroma.from_documents(documents = all_splits, embedding = embedding, persist_directory=embedding_vector_db_path)\n",
        "retriever = vectorstore.as_retriever(search_type = \"similarity\", search_kwargs = {\"k\" : 6})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIax-u7dteI-"
      },
      "source": [
        "# Existing Vector DB load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "vectorstore = Chroma(persist_directory=embedding_vector_db_path, embedding_function=embedding)\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwEXPtmGltXK"
      },
      "outputs": [],
      "source": [
        "# from langchain.vectorstores import Chroma\n",
        "\n",
        "# # Load existing vector store (you don't need to recreate it)\n",
        "# vectorstore = Chroma(persist_directory='db/nomic/semantic/',embedding_function=embedding)\n",
        "# retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APr4HNY9pHg6"
      },
      "outputs": [],
      "source": [
        "#@title prompt template\n",
        "\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "Use the following context to answer the question clearly and simply:\n",
        "{context}\n",
        "Answer the question based on the above context: {question}.\n",
        "Provide a detailed answer.\n",
        "Do not justify your answers.\n",
        "Please explain using simple language, relevant examples, and avoid jargon.\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uJJCPCKPrDs"
      },
      "outputs": [],
      "source": [
        "llm = get_ollama_model(\"llama3.2:1b\")\n",
        "# prompt = process_query(\"explain newtons first law with example\")\n",
        "# response = llm(prompt)\n",
        "# print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "pw-q37-1O5yQ",
        "outputId": "f84b3bb3-7bab-47ee-8847-2df9677ddc2e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Newton\\'s First Law of Motion, also known as the Law of Inertia, states that an object at rest will remain at rest, and an object in motion will continue to move with a constant velocity, unless acted upon by an external force.\\n\\nHere\\'s a simple example to illustrate this concept:\\n\\n**Example: A Basketball Player on the Court**\\n\\nImagine a basketball player named John who is sitting on the court, watching a game. He has just taken his seat and is enjoying the game. Suddenly, the coach calls out to him, \"John, come over here and try your shot!\"\\n\\nJohn gets up from his seat and walks towards the coach\\'s bench. As he approaches, he feels the urge to sit back down again. The urge is strong, but John is not moving.\\n\\n**Initial State:**\\nJohn is at rest (not moving) on the court.\\n\\n**Applying a Force:**\\nThe coach calls out to him, applying an external force (a push or shove). This force causes John to suddenly get up from his seat and walk towards the bench.\\n\\n**Result:**\\nAs John moves towards the bench, he maintains his velocity (speed) of 0 m/s (since he\\'s not accelerating). He continues moving in a straight line until he reaches the bench. Once on the bench, he can choose to sit back down again or continue walking.\\n\\n**Key Points:**\\n\\n* If there was no external force applied to John, he would remain at rest and follow his natural tendency to stay seated.\\n* The coach\\'s push or shove applied an external force that caused John to change direction.\\n* John\\'s velocity didn\\'t change; only his state of motion (being on the bench) changed.\\n\\n**Newton\\'s First Law in Action:**\\nIn this example, Newton\\'s First Law is at work. The external force (the coach\\'s push) was necessary to cause John to accelerate (change his state of motion). Without the force, John would have remained stationary and followed his natural tendency to stay seated.\\n\\nThis simple example illustrates how Newton\\'s First Law helps us understand that objects tend to maintain their state of motion unless an external force acts upon them.'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(\"explain newtons first law with example\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZ5xnvObmHDl",
        "outputId": "c87a703a-d1de-4394-b6fe-99dd1120bb76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Newton's First Law explains that an object will keep moving in its current direction unless something else is applied to it.\n",
            "\n",
            "Imagine you're playing a game where you throw a ball straight up in the air. What happens? The ball comes back down to the ground and lands in your hand, right?\n",
            "\n",
            "That's because the force you applied by throwing the ball (up) kept it moving in that same direction until something else came along and changed its motion.\n",
            "\n",
            "Let's use an example: Imagine a car going on a straight road. If no one pushes or pulls the car, it will keep driving forward. But if someone hits the brakes suddenly, the car will start slowing down and eventually stop.\n",
            "\n",
            "That's because the force of the brakes is acting on the car (pushing it backward), which changes its motion. The car can't just stop on its own; something has to apply a force to make it do so.\n",
            "\n",
            "Newton's First Law applies to all objects, big or small. It explains why things keep moving in their current direction unless someone or something else makes them change that direction.\n",
            "\n",
            "For example, when you're riding a bike, you have to pedal forward and backward to keep moving in a straight line. If you stop pedaling, the bike will just come to a stop. That's because the force of your pedaling (forward motion) keeps it moving in that direction until someone or something else stops it.\n",
            "\n",
            "Newton's First Law is all around us, from the way objects move on Earth to how cars and bikes work. It's an important idea that helps us understand how the world works!"
          ]
        }
      ],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# llm = get_ollama_model(\"gemma2:2b\")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "\n",
        "retrieval_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "for chunk in retrieval_chain.stream(\"explain newtons first law with example\"):\n",
        "    print(chunk, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AGr6eodunRp"
      },
      "source": [
        "Recall + Quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74ScZKCyuUXp"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Embedding size - assuming you are using the 'embedding_function' from Chroma\n",
        "embedding_size = embedding._embedding_fn.model.config.hidden_size  # For transformers-based models\n",
        "\n",
        "# Step 1: Measure recall time of chunks\n",
        "start_time = time.time()\n",
        "retrieved_docs = retriever.get_relevant_documents(\"explain newtons first law with example\")\n",
        "end_time = time.time()\n",
        "\n",
        "recall_time = end_time - start_time\n",
        "print(f\"Recall time: {recall_time:.4f} seconds\")\n",
        "\n",
        "# Step 2: Calculate embedding quality (Cosine similarity)\n",
        "def calculate_embedding_quality(query_embedding, retrieved_embeddings):\n",
        "    # Calculate cosine similarity between the query embedding and the retrieved embeddings\n",
        "    similarities = cosine_similarity([query_embedding], retrieved_embeddings)\n",
        "\n",
        "    # Average similarity score\n",
        "    avg_similarity = np.mean(similarities)\n",
        "    return avg_similarity\n",
        "\n",
        "# Simulating query embedding and retrieved embeddings for this example\n",
        "query_embedding = embedding.embed_query(\"explain newtons first law with example\")\n",
        "retrieved_embeddings = [doc.embedding for doc in retrieved_docs]\n",
        "\n",
        "# Step 3: Calculate embedding quality\n",
        "embedding_quality = calculate_embedding_quality(query_embedding, retrieved_embeddings)\n",
        "print(f\"Embedding Quality (Average Cosine Similarity): {embedding_quality:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1789b8c51c4b48118e34ffedce61dd47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56aec4fb098b461cabab190b64dd9373": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7119cc97380a473f88c28732b2c0b484": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cc1bb1287a747e58598d42e08845476": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95baf5e616ed4254a8073da5a4577320",
            "placeholder": "",
            "style": "IPY_MODEL_1789b8c51c4b48118e34ffedce61dd47",
            "value": "547M/547M[00:03&lt;00:00,156MB/s]"
          }
        },
        "8e69cc838456455c8953a41b28503dab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2652477e7c04bc9965b80f96e2caf16",
            "max": 546938168,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c607deeff00b4e3a976493ed9a3c603d",
            "value": 546938168
          }
        },
        "8f0cb74e78764a89acffa3a4e818e888": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7119cc97380a473f88c28732b2c0b484",
            "placeholder": "",
            "style": "IPY_MODEL_56aec4fb098b461cabab190b64dd9373",
            "value": "model.safetensors:100%"
          }
        },
        "95baf5e616ed4254a8073da5a4577320": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cfbbcde5fbc4edca77c0eef1c705d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f0cb74e78764a89acffa3a4e818e888",
              "IPY_MODEL_8e69cc838456455c8953a41b28503dab",
              "IPY_MODEL_7cc1bb1287a747e58598d42e08845476"
            ],
            "layout": "IPY_MODEL_f17e27493b4846e1ab086ea7a6f7654e"
          }
        },
        "c2652477e7c04bc9965b80f96e2caf16": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c607deeff00b4e3a976493ed9a3c603d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f17e27493b4846e1ab086ea7a6f7654e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
